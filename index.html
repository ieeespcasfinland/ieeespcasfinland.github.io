<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>  2021 IEEE SPS Cycle 2 School on   Networked Federated Learning: Theory, Algorithms and Applications</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1><br /> 2021 IEEE SPS Cycle 2 School on <br /><br /> Networked Federated Learning: Theory, Algorithms and Applications</h1>
</div>
<p>This school teaches basic theory and algorithms for networked <a href="https://en.wikipedia.org/wiki/Federated_learning" target="_blank">federated learning (FL)</a>. Networked federated learning aims at learning tailored (personalized) models for local datasets that are related by some network structure. Such networked data arises in pandemics where local datasets are collected by smartphones or wearables of humans. These local datasets are related by different networks such as contact networks or co-morbidity networks. Networked federated learning allows to learn personalized models for predicting the individual risk of a Covid-19 infection based on the local datasets of contact persons. </p>
<h3>Prerequisites: </h3>
<ul>
<li><p>basic knowledge in programming with Python: flow control, functions, numpy-arrays</p>
</li>
<li><p>linear algebra: vectors, matrices, eigenvalues</p>
</li>
</ul>
<h2>Learning Outcomes:</h2>
<p>After completing the school, participants </p>
<ul>
<li><p>are familiar with the concept of regularized empirical risk minimization (RERM)</p>
</li>
<li><p>understand the principle of gradient descent for solving RERM </p>
</li>
<li><p>can implement basic ML methods in Python </p>
</li>
<li><p>can use graphs to represent networked data and ML models </p>
</li>
<li><p>can apply and critically evaluate federated learning methods</p>
</li>
</ul>
<h2>Tentative Schedule </h2>
<p>Each day consists of lectures and exercises. </p>
<p><table>
<tr>
<td>Mo. 28.03.</td>
<td>Tue. 29.03.</td>
<td>Wed. 30.03.</td>
<td>Th.  31.03.</td>
<td>Fr.  01.04.</td>
</tr>
<tr style=font-size:20px>
<td>  <b> Machine Learning </b> </td>
<td> <b> Networks</b></td>
<td><b> Federated Learning</b></td>
<td><b> Clustered Federated Learning</b></td>
<td><b>  Advanced Topics</b></td>
</tr>
<tr>
<td style="text-align:left"> Data, Model, Loss</td>
<td style="text-align:left"> Graphs and their Matrices</td>
<td style="text-align:left"> Networked Data </td>
<td style="text-align:left"> Networked Models </td>
<td style="text-align:left"> Privacy-Preservation</td>
</tr>
<tr>
<td style="text-align:left">Linear and Logistic Regression </td>
<td style="text-align:left">Spectrum of Laplacian</td>
<td style="text-align:left"> Centralized Federated learning  </td>
<td style="text-align:left"> Total Variation Minimization</td>
<td style="text-align:left"> Inter- and Explainability </td>
</tr>
<tr>
<td style="text-align:left"> Stoch. Gradient Descent </td>
<td style="text-align:left">Cluster Structure</td>
<td style="text-align:left"> Gossip, Consensus </td>
<td style="text-align:left"> Distributed SGD </td>
<td style="text-align:left"> Legal Aspects </td>
</tr>
</table></p>
<h2>References</h2>
<ul>
<li><p>S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, &ldquo;Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers,&rdquo; Foundations and Trends in Machine Learning, 3(1):1–122, 2011.</p>
</li>
<li><p>D. A. Spielman, &ldquo;Spectral and Algebraic Graph Theory,&rdquo; Incomplete Draft, Yale University, 2019 <a href="http://cs-www.cs.yale.edu/homes/spielman/sagt/sagt.pdf" target="_blank">weblink</a>.</p>
</li>
<li><p>A. Jung, &ldquo;Federated Learning Over Networks for Pandemics,&rdquo; LiveProject, Manning Publishers, 2021 <a href="https://www.manning.com/liveprojectseries/federated-learning-ser" target="_blank">weblink</a>.</p>
</li>
<li><p>A. Jung, &ldquo;Machine Learning: The Basics,&rdquo; Springer, Singapore, 2022. draft:  <a href="https://mlbook.cs.aalto.fi" target="_blank">draft</a>.</p>
</li>
</ul>
<div class="infoblock">
<div class="blocktitle"></div>
<div class="blockcontent">
<h3>Organizing Committee: </h3>
<p><table style="border:hidden;">
<th> 
<a href="https://users.aalto.fi/~junga1/" target="_blank"> Dr. Alex Jung</a>
</th>
<th> <a href="https://users.aalto.fi/~ssarkka/" target="_blank"> Dr. Simo Särkkä</a> </th>
<th> <a href="https://jntukucev.ac.in/department/electronics-communication-engineering/dr-tummala-surya-narayana-murthy/" target="_blank"> Dr. T.S.N. Murthy </a> </th>
</tr>
<tr style="border:hidden;" align="left">
<td style="text-align:left">Ass. Prof. at Aalto U.</td>
<td style="text-align:left">Assoc. Prof. at Aalto U.</td>
<td style="text-align:left">Ass. Prof. JNTUK Vizianagaram </td>
</tr>
<tr style="border:hidden;">
<td>IEEE Finland Chapter SP/CAS</td>
<td>IEEE Finland Chapter CSS/RAS/SMCS</td>
<td>IEEE Vizag Bay Chapter COMSOC/SPS </td>
</tr>
</table></p>
<h3>Registration:</h3>
<p><a href="https://events.vtools.ieee.org/event/register/297208" target="_blank">Click here for a free registration.</a>  </p>
<h3>Acknowledgment </h3>
<p>This seasonal school is supported by the TalTech Industrial project. TalTech Industrial has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 952410.</p>
<p><img src="horizon2020.png" alt="logo" height="200"> <img src="aaltologo.png" alt="logo" height="200"> <img src="SPS_Logo_Color_RGB.png" alt="logo" height="200">   </p>
<div id="footer">
<div id="footer-text">
Page generated 2022-01-29 21:15:26 EET, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
