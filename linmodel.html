<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>  2021 IEEE SPS Cycle 2 School on   Networked Federated Learning: Theory, Algorithms and Applications</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1><br /> 2021 IEEE SPS Cycle 2 School on <br /><br /> Networked Federated Learning: Theory, Algorithms and Applications</h1>
</div>
<h1>Linear and Logistic Regression </h1>
<p>This module explains two widely used ML methods that both use the same model. This model consists of linear maps applied to a feature vector. The parameters of this linear model are chosen by minimising the average loss incurred on a training set. Linear regression uses the squared error loss which is well suited for numeric label values. Logistic regression uses the logistic loss which is well suited for binary classification problems. </p>
<h2>Learning Outcomes</h2>
<p>After completing this module, participants </p>
<ul>
<li><p>know about the linear model as a parametrized space of linear maps </p>
</li>
<li><p>know basic properties of squared error loss and logistic loss </p>
</li>
<li><p>can use Python to learn linear maps for regression or binary classification </p>
</li>
</ul>
<h2>Reading Assignment</h2>
<p>Section 3.1 and 3.6 of <a href="https://mlbook.cs.aalto.fi" target="_blank"> A. Jung, "Machine Learning: The Basics", Springer, 2022 </a></p>
<h2>Additional Material </h2>
<p><a href="https://youtube.com/playlist?list=PLrbn2dGrLJK-1s3DTfi7ZXxaB5lkIRHHM" target="_blank"> YouTube Playlist </a></p>
<h2>Exercise</h2>
<p>TBA</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-02-07 10:55:39 CET, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
