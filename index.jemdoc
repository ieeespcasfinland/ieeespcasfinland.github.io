= \n 2021 IEEE SPS Cycle 2 School on \n\n Networked Federated Learning: Theory, Algorithms and Applications

This school teaches theoretic underpinnings and practical algorithms for networked {{<a href="https://en.wikipedia.org/wiki/Federated_learning" target="_blank">federated learning (FL)</a>}}. Networked FL provides tailored (personalized) models for local datasets that are related by some {{<a href="https://en.wikipedia.org/wiki/Complex_network" target="_blank">complex network structure</a>}}. Such networked data arises in several important application domains such as pandemics or the industrial internet of things. 

=== Prerequisites: 
- basic knowledge in programming with Python: flow control, functions, numpy-arrays
- linear algebra: vectors, matrices, eigenvalues

=== Learning Outcomes:
After completing the school, participants 
- are familiar with the concept of regularized empirical risk minimization (RERM)
- understand the principle of gradient descent for solving RERM 
- can implement basic ML methods in Python 
- can use graphs to represent networked data and ML models 
- can apply and critically evaluate FL methods

== Tentative Schedule 
Each day consists of lectures and exercises. 

{{<table>
  <tr>
    <td>Mo. 28.03.</td>
    <td>Tue. 29.03.</td>
    <td>Wed. 30.03.</td>
    <td>Th.  31.03.</td>
    <td>Fr.  01.04.</td>
  </tr>
  <tr style=font-size:20px>
    <td>  <b> Machine Learning </b> </td>
    <td> <b> Networks</b></td>
    <td><b>  Basic FL</b></td>
    <td><b> Clustered FL</b></td>
    <td><b> Trustworthy FL </b></td>
  </tr>
  <tr>
    <td style="text-align:left"> <a href="DataModelLoss.html" target="_blank"> Data, Model, Loss</a></td>
    <td style="text-align:left"> Graphs and their Matrices</td>
    <td style="text-align:left"> Networked Data </td>
    <td style="text-align:left"> Networked Models </td>
    <td style="text-align:left"> Privacy-Preservation</td>
  </tr>
  <tr>
    <td style="text-align:left"> Linear and Logistic Regression </td>
    <td style="text-align:left"> Spectrum of Laplacian</td>
    <td style="text-align:left"> Centralized FL  </td>
    <td style="text-align:left"> Total Variation Minimization</td>
    <td style="text-align:left"> Explainability </td>
  </tr>
  <tr>
    <td style="text-align:left"> Gradient-Based Learning </td>
    <td style="text-align:left"> Cluster Structure</td>
    <td style="text-align:left"> Gossip, Consensus </td>
    <td style="text-align:left"> Distributed SGD </td>
    <td style="text-align:left"> Legal Aspects </td>
  </tr>
</table>}}

== References

- Cui, S., Hero, III, A., Luo, Z., & Moura, J. (Eds.). (2016). Big Data over Networks. Cambridge: Cambridge University Press. doi:10.1017/CBO9781316162750
- S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers," Foundations and Trends in Machine Learning, 3(1):1–122, 2011. {{<a href="https://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf" target="_blank">weblink</a>.}}
- D. A. Spielman, "Spectral and Algebraic Graph Theory," Incomplete Draft, Yale University, 2019 {{<a href="http://cs-www.cs.yale.edu/homes/spielman/sagt/sagt.pdf" target="_blank">weblink</a>.}}
- A. Jung, "Federated Learning Over Networks for Pandemics," LiveProject, Manning Publishers, 2021 {{<a href="https://www.manning.com/liveprojectseries/federated-learning-ser" target="_blank">weblink</a>.}}
- A. Jung, "Machine Learning: The Basics," Springer, Singapore, 2022. {{<a href="https://mlbook.cs.aalto.fi" target="_blank">draft</a>.}}
~~~
{} 

=== Organizing Committee: 

{{<table style="border:hidden;">
    <th> 
<a href="https://users.aalto.fi/~junga1/" target="_blank"> Dr. Alex Jung</a>
</th>
 <th> <a href="https://users.aalto.fi/~ssarkka/" target="_blank"> Dr. Simo Särkkä</a> </th>
  <th> <a href="https://jntukucev.ac.in/department/electronics-communication-engineering/dr-tummala-surya-narayana-murthy/" target="_blank"> Dr. T.S.N. Murthy </a> </th>
  </tr>
  <tr style="border:hidden;" align="left">
    <td style="text-align:left">Ass. Prof. at Aalto U.</td>
    <td style="text-align:left">Assoc. Prof. at Aalto U.</td>
    <td style="text-align:left">Ass. Prof. JNTUK Vizianagaram </td>
  </tr>
  <tr style="border:hidden;">
    <td>IEEE Finland Chapter SP/CAS</td>
    <td>IEEE Finland Chapter CSS/RAS/SMCS</td>
    <td>IEEE Vizag Bay Chapter COMSOC/SPS </td>
  </tr>
</table>}}

=== Registration:
{{<a href="https://events.vtools.ieee.org/event/register/297208" target="_blank">Click here for a free registration.</a>}}  

=== Acknowledgment 
This seasonal school is supported by the IEEE Signal Processing Society and the Department of Computer Science at Aalto University. The school is also supported by the TalTech Industrial project. TalTech Industrial has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 952410. We also acknowledge support received from the Academy of Finland, via the project ‘‘Intelligent Techniques in Condition Monitoring of Electromechanical Energy Conversion Systems,’’ (decision number 331197). 

 {{ <img src="SPS_Logo_Color_RGB.png" alt="logo" height="100"> <img src="aaltologo.png" alt="logo" height="100"> <img src="horizon2020.png" alt="logo" height="100">  <img src="AoFLogo.png" alt="logo" height="100"> }}  


